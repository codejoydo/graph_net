

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Predicting next time point shuffled across participants &#8212; Graph Networks on fMRI</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Linear Regression for timeseries simulation" href="Linear_Regression_timeseries_simulation.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  
  <h1 class="site-logo" id="site-title">Graph Networks on fMRI</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="NLNN_intro.html">
   What is NLNN?
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Experiments with NLNN
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="NLNN_Clip_Classifier.html">
   Clip Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NLNN_CC_Randomization.html">
   Breaking Down Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NLNN_timeseries_simulation.html">
   Timeseries Simulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Linear_Regression_timeseries_simulation.html">
   Linear Regression for timeseries simulation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Predicting next time point shuffled across participants
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/NLNN_timeseries_simulation_randomdata.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/codejoydo/graph_net"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/codejoydo/graph_net/issues/new?title=Issue%20on%20page%20%2FNLNN_timeseries_simulation_randomdata.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/codejoydo/graph_net/edit/master/NLNN_timeseries_simulation_randomdata.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data">
   Load data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-graphs-from-data">
   Create graphs from data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance-evaluation">
   Performance evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-training">
     Model training
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="predicting-next-time-point-shuffled-across-participants">
<h1>Predicting next time point shuffled across participants<a class="headerlink" href="#predicting-next-time-point-shuffled-across-participants" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="load-data">
<h2>Load data<a class="headerlink" href="#load-data" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load dataset </span>
<span class="n">X</span><span class="p">,</span> <span class="n">X_len</span><span class="p">,</span> <span class="n">clip_y</span><span class="p">,</span> <span class="n">num_subjs</span><span class="p">,</span> <span class="n">num_clips</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>

<span class="c1"># clip names</span>
<span class="n">clip_name_to_idx</span> <span class="o">=</span> <span class="n">_get_clip_labels</span><span class="p">()</span>
<span class="n">clip_idx_to_name</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">clip_name_to_idx</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">clip_idx_to_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">clip_idx_to_name</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># get rid of run number in test-retest</span>
<span class="n">clip_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">clip_idx_to_name</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="c1"># # Pad each time-series with zeros to equalize lengths</span>
<span class="c1"># X = pad_data(X)</span>

<span class="c1"># Fix a clip for simulating its trajectory</span>
<span class="n">clip_num</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">X_clip</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">clip_y</span><span class="p">))</span> <span class="k">if</span> <span class="n">clip_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">clip_num</span><span class="p">]</span>
<span class="n">y_clip</span> <span class="o">=</span> <span class="p">[</span><span class="n">clip_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">clip_y</span><span class="p">))</span> <span class="k">if</span> <span class="n">clip_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">clip_num</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loading run 1/1
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="create-graphs-from-data">
<h2>Create graphs from data<a class="headerlink" href="#create-graphs-from-data" title="Permalink to this headline">Â¶</a></h2>
<p>Here we use a history of length k = 5.</p>
<p>As a control analysis, we set the time-series of each participant as a random <span class="math notranslate nohighlight">\(#time \times #ROI\)</span> matrix.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create data </span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># Length of memory/history of data-sequence </span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">shuffled_subjs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">num_subjs</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx_subj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_subjs</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">X_clip</span><span class="p">[</span><span class="n">idx_subj</span><span class="p">]</span>
    <span class="n">x_shuffled</span> <span class="o">=</span> <span class="n">X_clip</span><span class="p">[</span><span class="n">shuffled_subjs</span><span class="p">[</span><span class="n">idx_subj</span><span class="p">]]</span>
    <span class="k">for</span> <span class="n">idx_tp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">8448</span><span class="p">:</span>
            <span class="n">x_tp</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx_tp</span> <span class="o">-</span> <span class="n">k</span> <span class="p">:</span> <span class="n">idx_tp</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_tp</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx_tp</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_tp</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">idx_tp</span> <span class="o">-</span> <span class="n">k</span> <span class="p">:</span> <span class="n">idx_tp</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_tp</span> <span class="o">=</span> <span class="n">x_shuffled</span><span class="p">[</span><span class="n">idx_tp</span><span class="p">,</span> <span class="p">:]</span>    
        <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_tp</span><span class="p">)</span>
        <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_tp</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>        
        
<span class="c1"># Create graphs from data</span>
<span class="n">prob_edge</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">graphs_dict_list</span> <span class="o">=</span> <span class="n">clip_graphs</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> 
                               <span class="n">prob_edge</span><span class="o">=</span><span class="n">prob_edge</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="performance-evaluation">
<h2>Performance evaluation<a class="headerlink" href="#performance-evaluation" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="model-training">
<h3>Model training<a class="headerlink" href="#model-training" title="Permalink to this headline">Â¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train, test split</span>
<span class="n">num_X</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="n">num_X</span><span class="p">)</span>
<span class="n">num_val</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">*</span> <span class="n">num_X</span>
<span class="n">num_test</span> <span class="o">=</span> <span class="n">num_X</span> <span class="o">-</span> <span class="n">num_train</span> <span class="o">-</span> <span class="n">num_val</span>

<span class="n">num_splits</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">test_accuracy_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">idx_split</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">):</span>
    
    <span class="c1"># Shuffle data for random train-test splits</span>
<span class="c1">#     rand_idx = np.rand_perm = np.random.permutation(num_X)</span>
<span class="c1">#     graphs_dict_list_perm = list(map(lambda i: graphs_dict_list[i], rand_idx))</span>
<span class="c1">#     y_perm = y[rand_idx, :]</span>
    <span class="n">graphs_dict_list_perm</span> <span class="o">=</span> <span class="n">graphs_dict_list</span>
    <span class="n">y_perm</span> <span class="o">=</span> <span class="n">y</span>
    
    <span class="c1"># Create split</span>
    <span class="n">train_G</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_G</span><span class="p">,</span> <span class="n">val_y</span><span class="p">,</span> <span class="n">test_G</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">train_val_test_split</span><span class="p">(</span><span class="n">graphs_dict_list_perm</span><span class="p">,</span>
                                                                           <span class="n">y_perm</span><span class="p">,</span>
                                                                           <span class="n">num_train</span><span class="p">,</span>
                                                                           <span class="n">num_val</span><span class="p">,</span>
                                                                           <span class="n">num_test</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">NLNNProcessDecode</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">=</span><span class="n">train_G</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;nodes&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                              <span class="n">k_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">],</span> 
                              <span class="n">num_processing_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="n">graph_slice</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="p">:</span> <span class="n">utils_tf</span><span class="o">.</span><span class="n">data_dicts_to_graphs_tuple</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">end</span><span class="p">])</span>
    
    <span class="n">NLNN_simulator</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">(</span><span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;regression&quot;</span><span class="p">,</span>
                                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                                <span class="n">loss_object</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
                                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
                                <span class="n">eval_metric</span><span class="o">=</span><span class="n">tfa</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">RSquare</span><span class="p">(),</span>
                                <span class="n">eval_metric_name</span><span class="o">=</span><span class="s2">&quot;% var explained&quot;</span><span class="p">,</span>
                                <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                                <span class="n">slice_input</span><span class="o">=</span><span class="n">graph_slice</span><span class="p">)</span>
    
    <span class="n">results</span> <span class="o">=</span> <span class="n">NLNN_simulator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="o">=</span><span class="n">train_G</span><span class="p">,</span>
                                 <span class="n">train_Y</span><span class="o">=</span><span class="n">train_y</span><span class="p">,</span>
                                 <span class="n">val_X</span><span class="o">=</span><span class="n">test_G</span><span class="p">,</span>
                                 <span class="n">val_Y</span><span class="o">=</span><span class="n">test_y</span><span class="p">,</span>
                                 <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 000: Train Loss: 436.135, Train % var explained: -32331.259%  Val Loss: 5.431, Val % var explained: -467.990%  
Epoch 001: Train Loss: 3.598, Train % var explained: -265.226%  Val Loss: 2.243, Val % var explained: -134.422%  
Epoch 002: Train Loss: 2.140, Train % var explained: -119.272%  Val Loss: 1.593, Val % var explained: -66.362%  
Epoch 003: Train Loss: 1.668, Train % var explained: -71.003%  Val Loss: 1.328, Val % var explained: -38.565%  
Epoch 004: Train Loss: 1.440, Train % var explained: -47.602%  Val Loss: 1.203, Val % var explained: -25.459%  
Epoch 005: Train Loss: 1.310, Train % var explained: -34.159%  Val Loss: 1.114, Val % var explained: -16.129%  
Epoch 006: Train Loss: 1.225, Train % var explained: -25.337%  Val Loss: 1.018, Val % var explained: -6.211%  
Epoch 007: Train Loss: 1.167, Train % var explained: -19.273%  Val Loss: 0.941, Val % var explained: 1.839%  
Epoch 008: Train Loss: 1.126, Train % var explained: -15.017%  Val Loss: 0.893, Val % var explained: 6.762%  
Epoch 009: Train Loss: 1.095, Train % var explained: -11.787%  Val Loss: 0.882, Val % var explained: 7.953%  
Epoch 010: Train Loss: 1.069, Train % var explained: -9.136%  Val Loss: 0.895, Val % var explained: 6.584%  
Epoch 011: Train Loss: 1.048, Train % var explained: -6.932%  Val Loss: 0.905, Val % var explained: 5.619%  
Epoch 012: Train Loss: 1.031, Train % var explained: -5.205%  Val Loss: 0.898, Val % var explained: 6.359%  
Epoch 013: Train Loss: 1.019, Train % var explained: -3.906%  Val Loss: 0.884, Val % var explained: 7.818%  
Epoch 014: Train Loss: 1.010, Train % var explained: -2.920%  Val Loss: 0.875, Val % var explained: 8.778%  
Epoch 015: Train Loss: 1.003, Train % var explained: -2.193%  Val Loss: 0.879, Val % var explained: 8.362%  
Epoch 016: Train Loss: 1.000, Train % var explained: -1.709%  Val Loss: 0.897, Val % var explained: 6.570%  
Epoch 017: Train Loss: 0.998, Train % var explained: -1.435%  Val Loss: 0.920, Val % var explained: 4.245%  
Epoch 018: Train Loss: 0.997, Train % var explained: -1.303%  Val Loss: 0.942, Val % var explained: 1.914%  
Epoch 019: Train Loss: 0.997, Train % var explained: -1.225%  Val Loss: 0.965, Val % var explained: -0.358%  
Epoch 020: Train Loss: 0.997, Train % var explained: -1.144%  Val Loss: 0.982, Val % var explained: -2.100%  
Epoch 021: Train Loss: 0.997, Train % var explained: -1.056%  Val Loss: 0.987, Val % var explained: -2.592%  
Epoch 022: Train Loss: 0.997, Train % var explained: -0.956%  Val Loss: 0.975, Val % var explained: -1.393%  
Epoch 023: Train Loss: 0.996, Train % var explained: -0.815%  Val Loss: 0.947, Val % var explained: 1.492%  
Epoch 024: Train Loss: 0.994, Train % var explained: -0.621%  Val Loss: 0.908, Val % var explained: 5.584%  
Epoch 025: Train Loss: 0.992, Train % var explained: -0.397%  Val Loss: 0.865, Val % var explained: 10.034%  
Epoch 026: Train Loss: 0.990, Train % var explained: -0.171%  Val Loss: 0.827, Val % var explained: 14.021%  
Epoch 027: Train Loss: 0.988, Train % var explained: 0.041%  Val Loss: 0.797, Val % var explained: 17.173%  
Epoch 028: Train Loss: 0.987, Train % var explained: 0.234%  Val Loss: 0.774, Val % var explained: 19.567%  
Epoch 029: Train Loss: 0.985, Train % var explained: 0.396%  Val Loss: 0.757, Val % var explained: 21.419%  
Epoch 030: Train Loss: 0.985, Train % var explained: 0.499%  Val Loss: 0.743, Val % var explained: 22.886%  
Epoch 031: Train Loss: 0.985, Train % var explained: 0.505%  Val Loss: 0.732, Val % var explained: 24.002%  
Epoch 032: Train Loss: 0.987, Train % var explained: 0.400%  Val Loss: 0.726, Val % var explained: 24.681%  
Epoch 033: Train Loss: 0.990, Train % var explained: 0.209%  Val Loss: 0.724, Val % var explained: 24.822%  
Epoch 034: Train Loss: 0.993, Train % var explained: -0.016%  Val Loss: 0.728, Val % var explained: 24.419%  
Epoch 035: Train Loss: 0.995, Train % var explained: -0.234%  Val Loss: 0.737, Val % var explained: 23.552%  
Epoch 036: Train Loss: 0.998, Train % var explained: -0.425%  Val Loss: 0.749, Val % var explained: 22.322%  
Epoch 037: Train Loss: 1.000, Train % var explained: -0.590%  Val Loss: 0.764, Val % var explained: 20.810%  
Epoch 038: Train Loss: 1.002, Train % var explained: -0.732%  Val Loss: 0.781, Val % var explained: 19.088%  
Epoch 039: Train Loss: 1.003, Train % var explained: -0.846%  Val Loss: 0.798, Val % var explained: 17.253%  
Epoch 040: Train Loss: 1.004, Train % var explained: -0.909%  Val Loss: 0.816, Val % var explained: 15.467%  
Epoch 041: Train Loss: 1.004, Train % var explained: -0.890%  Val Loss: 0.830, Val % var explained: 13.959%  
Epoch 042: Train Loss: 1.003, Train % var explained: -0.772%  Val Loss: 0.840, Val % var explained: 12.965%  
Epoch 043: Train Loss: 1.001, Train % var explained: -0.570%  Val Loss: 0.843, Val % var explained: 12.647%  
Epoch 044: Train Loss: 0.998, Train % var explained: -0.332%  Val Loss: 0.839, Val % var explained: 13.058%  
Epoch 045: Train Loss: 0.995, Train % var explained: -0.114%  Val Loss: 0.828, Val % var explained: 14.144%  
Epoch 046: Train Loss: 0.994, Train % var explained: 0.038%  Val Loss: 0.813, Val % var explained: 15.746%  
Epoch 047: Train Loss: 0.993, Train % var explained: 0.105%  Val Loss: 0.795, Val % var explained: 17.592%  
Epoch 048: Train Loss: 0.993, Train % var explained: 0.092%  Val Loss: 0.777, Val % var explained: 19.370%  
Epoch 049: Train Loss: 0.994, Train % var explained: 0.017%  Val Loss: 0.763, Val % var explained: 20.856%  
Epoch 050: Train Loss: 0.996, Train % var explained: -0.098%  Val Loss: 0.752, Val % var explained: 21.994%  
Epoch 051: Train Loss: 0.997, Train % var explained: -0.231%  Val Loss: 0.743, Val % var explained: 22.854%  
Epoch 052: Train Loss: 0.999, Train % var explained: -0.363%  Val Loss: 0.737, Val % var explained: 23.533%  
Epoch 053: Train Loss: 1.000, Train % var explained: -0.483%  Val Loss: 0.731, Val % var explained: 24.098%  
Epoch 054: Train Loss: 1.001, Train % var explained: -0.586%  Val Loss: 0.727, Val % var explained: 24.573%  
Epoch 055: Train Loss: 1.002, Train % var explained: -0.675%  Val Loss: 0.723, Val % var explained: 24.946%  
Epoch 056: Train Loss: 1.003, Train % var explained: -0.754%  Val Loss: 0.721, Val % var explained: 25.165%  
Epoch 057: Train Loss: 1.003, Train % var explained: -0.812%  Val Loss: 0.721, Val % var explained: 25.125%  
Epoch 058: Train Loss: 1.003, Train % var explained: -0.807%  Val Loss: 0.725, Val % var explained: 24.704%  
Epoch 059: Train Loss: 1.002, Train % var explained: -0.680%  Val Loss: 0.733, Val % var explained: 23.872%  
Epoch 060: Train Loss: 0.999, Train % var explained: -0.428%  Val Loss: 0.743, Val % var explained: 22.778%  
Epoch 061: Train Loss: 0.996, Train % var explained: -0.130%  Val Loss: 0.755, Val % var explained: 21.616%  
Epoch 062: Train Loss: 0.992, Train % var explained: 0.147%  Val Loss: 0.765, Val % var explained: 20.490%  
Epoch 063: Train Loss: 0.990, Train % var explained: 0.394%  Val Loss: 0.775, Val % var explained: 19.462%  
Epoch 064: Train Loss: 0.987, Train % var explained: 0.628%  Val Loss: 0.783, Val % var explained: 18.619%  
Epoch 065: Train Loss: 0.984, Train % var explained: 0.867%  Val Loss: 0.789, Val % var explained: 18.061%  
Epoch 066: Train Loss: 0.981, Train % var explained: 1.115%  Val Loss: 0.790, Val % var explained: 17.843%  
Epoch 067: Train Loss: 0.978, Train % var explained: 1.365%  Val Loss: 0.789, Val % var explained: 17.927%  
Epoch 068: Train Loss: 0.975, Train % var explained: 1.603%  Val Loss: 0.787, Val % var explained: 18.186%  
Epoch 069: Train Loss: 0.973, Train % var explained: 1.813%  Val Loss: 0.784, Val % var explained: 18.489%  
Epoch 070: Train Loss: 0.970, Train % var explained: 1.992%  Val Loss: 0.781, Val % var explained: 18.756%  
Epoch 071: Train Loss: 0.968, Train % var explained: 2.142%  Val Loss: 0.779, Val % var explained: 18.965%  
Epoch 072: Train Loss: 0.967, Train % var explained: 2.268%  Val Loss: 0.777, Val % var explained: 19.122%  
Epoch 073: Train Loss: 0.965, Train % var explained: 2.375%  Val Loss: 0.776, Val % var explained: 19.244%  
Epoch 074: Train Loss: 0.964, Train % var explained: 2.466%  Val Loss: 0.775, Val % var explained: 19.344%  
Epoch 075: Train Loss: 0.963, Train % var explained: 2.545%  Val Loss: 0.774, Val % var explained: 19.434%  
Epoch 076: Train Loss: 0.962, Train % var explained: 2.615%  Val Loss: 0.773, Val % var explained: 19.518%  
Epoch 077: Train Loss: 0.961, Train % var explained: 2.681%  Val Loss: 0.773, Val % var explained: 19.594%  
Epoch 078: Train Loss: 0.960, Train % var explained: 2.746%  Val Loss: 0.772, Val % var explained: 19.658%  
Epoch 079: Train Loss: 0.959, Train % var explained: 2.814%  Val Loss: 0.771, Val % var explained: 19.709%  
Epoch 080: Train Loss: 0.958, Train % var explained: 2.887%  Val Loss: 0.771, Val % var explained: 19.755%  
Epoch 081: Train Loss: 0.957, Train % var explained: 2.966%  Val Loss: 0.770, Val % var explained: 19.819%  
Epoch 082: Train Loss: 0.955, Train % var explained: 3.051%  Val Loss: 0.769, Val % var explained: 19.937%  
Epoch 083: Train Loss: 0.954, Train % var explained: 3.141%  Val Loss: 0.767, Val % var explained: 20.131%  
Epoch 084: Train Loss: 0.953, Train % var explained: 3.235%  Val Loss: 0.764, Val % var explained: 20.388%  
Epoch 085: Train Loss: 0.952, Train % var explained: 3.331%  Val Loss: 0.762, Val % var explained: 20.679%  
Epoch 086: Train Loss: 0.950, Train % var explained: 3.425%  Val Loss: 0.759, Val % var explained: 20.982%  
Epoch 087: Train Loss: 0.949, Train % var explained: 3.511%  Val Loss: 0.755, Val % var explained: 21.309%  
Epoch 088: Train Loss: 0.948, Train % var explained: 3.586%  Val Loss: 0.752, Val % var explained: 21.680%  
Epoch 089: Train Loss: 0.947, Train % var explained: 3.646%  Val Loss: 0.748, Val % var explained: 22.093%  
Epoch 090: Train Loss: 0.946, Train % var explained: 3.690%  Val Loss: 0.744, Val % var explained: 22.486%  
Epoch 091: Train Loss: 0.946, Train % var explained: 3.714%  Val Loss: 0.742, Val % var explained: 22.733%  
Epoch 092: Train Loss: 0.946, Train % var explained: 3.712%  Val Loss: 0.742, Val % var explained: 22.700%  
Epoch 093: Train Loss: 0.946, Train % var explained: 3.667%  Val Loss: 0.746, Val % var explained: 22.314%  
Epoch 094: Train Loss: 0.947, Train % var explained: 3.560%  Val Loss: 0.753, Val % var explained: 21.607%  
Epoch 095: Train Loss: 0.948, Train % var explained: 3.400%  Val Loss: 0.761, Val % var explained: 20.796%  
Epoch 096: Train Loss: 0.949, Train % var explained: 3.311%  Val Loss: 0.765, Val % var explained: 20.397%  
Epoch 097: Train Loss: 0.947, Train % var explained: 3.466%  Val Loss: 0.762, Val % var explained: 20.665%  
Epoch 098: Train Loss: 0.943, Train % var explained: 3.732%  Val Loss: 0.757, Val % var explained: 21.147%  
Epoch 099: Train Loss: 0.941, Train % var explained: 3.929%  Val Loss: 0.753, Val % var explained: 21.580%  
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_loss_results</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">train_pve_results</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">test_loss_results</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">test_pve_results</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Training metrics</span>
<span class="n">fig_tr</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig_tr</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Training Metrics&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;log(Loss)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">train_loss_results</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Percentage Variance Explained&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_pve_results</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Validation metrics</span>
<span class="n">fig_val</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig_val</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Validation Metrics&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;log(Loss)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">test_loss_results</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Percentage Variance Explained&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_pve_results</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/NLNN_timeseries_simulation_randomdata_10_0.png" src="_images/NLNN_timeseries_simulation_randomdata_10_0.png" />
<img alt="_images/NLNN_timeseries_simulation_randomdata_10_1.png" src="_images/NLNN_timeseries_simulation_randomdata_10_1.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Linear_Regression_timeseries_simulation.html" title="previous page">Linear Regression for timeseries simulation</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Govinda and Joyneel<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>